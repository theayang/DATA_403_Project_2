{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6750e4bf-19ec-4d5f-8156-1722ece3cf44",
   "metadata": {},
   "source": [
    "## Data Cleaning\n",
    "### Thea Yang, Nick Gammal, Nick Hausman, Charlie Ward\n",
    "\n",
    "Cleaning file: `application_train.csv`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "999250e7-71f2-4b21-b3ed-d1fffaa6c4df",
   "metadata": {},
   "outputs": [],
   "source": [
    "#importing libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from Models import Logistic, Model\n",
    "PATH_EXTRA = 'home-credit-default-risk/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "e16cc62d-7d76-4be2-8812-a82f3a604e72",
   "metadata": {},
   "outputs": [],
   "source": [
    "# reading in data\n",
    "# df = pd.read_csv(\"application_train.csv\")\n",
    "df = pd.read_csv(PATH_EXTRA + \"application_train.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "af4b4910-d444-41ec-b65b-61cc3851727e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "dropping columns that either had too high correlation with other columns or \n",
    "too many missing obs that could not be imputed or modified\n",
    "\n",
    "see report for full description on decision to drop these columns\n",
    "\"\"\" \n",
    "df = df.drop(columns=['AMT_GOODS_PRICE', 'CNT_CHILDREN', 'FLAG_EMP_PHONE', 'REGION_RATING_CLIENT_W_CITY', \n",
    " 'REG_REGION_NOT_WORK_REGION', 'LIVE_CITY_NOT_WORK_CITY', 'LIVINGAPARTMENTS_MEDI', \n",
    " 'ELEVATORS_MEDI', 'OBS_60_CNT_SOCIAL_CIRCLE', 'DEF_60_CNT_SOCIAL_CIRCLE', 'LIVINGAREA_MEDI', 'EXT_SOURCE_1'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "6e0e5fce-3cd6-4477-9a37-567c18d8b146",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/yd/nfpg90257z743pz74p6rft340000gn/T/ipykernel_59311/3801100754.py:12: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  clean_df.fillna({'AMT_ANNUITY':mean_amt_annuity}, inplace=True)\n"
     ]
    }
   ],
   "source": [
    "# dropping obs for rows that have very little missing values or can't be modified and we still want to keep\n",
    "clean_df = df[df['DAYS_LAST_PHONE_CHANGE'].notnull() & \n",
    "   df['CNT_FAM_MEMBERS'].notnull() & \n",
    "   df['EXT_SOURCE_2'].notnull() & \n",
    "   df['DEF_30_CNT_SOCIAL_CIRCLE'].notnull() &\n",
    "   df['OBS_30_CNT_SOCIAL_CIRCLE'].notnull() &\n",
    "   df['EXT_SOURCE_3'].notnull()\n",
    "  ]\n",
    "\n",
    "# imputing amt ammunity column with mean amt\n",
    "mean_amt_annuity = clean_df.loc[:,'AMT_ANNUITY'].mean()\n",
    "clean_df.fillna({'AMT_ANNUITY':mean_amt_annuity}, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3da0115-5950-4bea-b768-e8ad5bb3ec24",
   "metadata": {},
   "source": [
    "### Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "13e22c8e-6fed-4fea-b053-78b3db7c9b9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def map_amt_req(c):\n",
    "    if c >= 1:\n",
    "        return 1\n",
    "    else:\n",
    "        return 0\n",
    "    \n",
    "# discretize own car age\n",
    "def agemap(num):\n",
    "    if num <= 1:\n",
    "        return \"new\"\n",
    "    elif num <= 5:\n",
    "        return \"young\"\n",
    "    elif num <= 10:\n",
    "        return \"middle\"\n",
    "    elif num <= 20:\n",
    "        return \"aging\"\n",
    "    elif num <= 60:\n",
    "        return \"old\"\n",
    "    elif num > 60:\n",
    "        return \"classic\"\n",
    "    else:\n",
    "        return \"no car\"\n",
    "\n",
    "# Refactor occupation type\n",
    "blue = [\"Laborers\", \"Drivers\", \"Medicine staff\", \"Security staff\", \"Cooking staff\", \"Cleaning staff\", \"Private service staff\", \"Low-skill Laborers\", \"Secretaries\", \"Waiters/barmen staff\"]\n",
    "white = [\"Sales staff\", \"Core staff\", \"Managers\", \"High skill tech staff\", \"Accountants\", \"Realty agents\", \"HR staff\", \"IT staff\"]\n",
    "def workmap(job):\n",
    "    if job in blue:\n",
    "        return \"blue\"\n",
    "    elif job in white:\n",
    "        return \"white\"\n",
    "    else:\n",
    "        return \"other\"\n",
    "    \n",
    "def accompany_map(c):\n",
    "    if c == 'Unaccompanied':\n",
    "        return 'Unaccompanied'\n",
    "    elif c in ['Family', 'Spouse, partner', 'Children', 'Other_B', 'Other_A', 'Group of people']:\n",
    "        return 'Accompanied'\n",
    "    else:\n",
    "        return 'Unknown'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "8667d1d2-da89-40a8-8eff-89efa5e9afa6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/yd/nfpg90257z743pz74p6rft340000gn/T/ipykernel_59311/4116833493.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  clean_df.loc[:, 'SUM_AMT_REQ_CREDIT'] = clean_df[['AMT_REQ_CREDIT_BUREAU_MON',\n",
      "/var/folders/yd/nfpg90257z743pz74p6rft340000gn/T/ipykernel_59311/4116833493.py:9: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  clean_df.loc[:, 'AMT_REQ_CREDIT']  = clean_df['SUM_AMT_REQ_CREDIT'].apply(map_amt_req)\n"
     ]
    }
   ],
   "source": [
    "# makng new column based on whether the person has made an enquiry to the Credit Bureau at all in the past year\n",
    "clean_df.loc[:, 'SUM_AMT_REQ_CREDIT'] = clean_df[['AMT_REQ_CREDIT_BUREAU_MON',\n",
    "'AMT_REQ_CREDIT_BUREAU_WEEK',\n",
    "'AMT_REQ_CREDIT_BUREAU_DAY',\n",
    "'AMT_REQ_CREDIT_BUREAU_HOUR',\n",
    "'AMT_REQ_CREDIT_BUREAU_QRT',\n",
    "'AMT_REQ_CREDIT_BUREAU_YEAR']].sum(axis=1)\n",
    "\n",
    "clean_df.loc[:, 'AMT_REQ_CREDIT']  = clean_df['SUM_AMT_REQ_CREDIT'].apply(map_amt_req)\n",
    "\n",
    "clean_df = clean_df.drop(columns=['AMT_REQ_CREDIT_BUREAU_WEEK',\n",
    "'AMT_REQ_CREDIT_BUREAU_DAY',\n",
    "'AMT_REQ_CREDIT_BUREAU_HOUR',\n",
    "'AMT_REQ_CREDIT_BUREAU_QRT',\n",
    "'AMT_REQ_CREDIT_BUREAU_YEAR',\n",
    "'AMT_REQ_CREDIT_BUREAU_MON',\n",
    "'SUM_AMT_REQ_CREDIT'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "1bfaa8e5-6db1-4ff5-8fde-080e89c503a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# remapping categorical columns to simplify levels and account for missing values\n",
    "clean_df['OCCUPATION_TYPE'] = clean_df['OCCUPATION_TYPE'].apply(workmap)\n",
    "clean_df['OWN_CAR_AGE'] = clean_df['OWN_CAR_AGE'].apply(agemap)\n",
    "clean_df['NAME_TYPE_SUITE']= clean_df['NAME_TYPE_SUITE'].apply(accompany_map)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "afe164e2-e08c-459f-b41b-a59a0e872e4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get all the 'housing-related' columns and keep only the median ones\n",
    "mode_cols = np.array(clean_df.columns[clean_df.columns.str.contains(\"_MODE\")])\n",
    "avg_cols = np.array(clean_df.columns[clean_df.columns.str.contains(\"_AVG\")])\n",
    "med_cols = np.array(clean_df.columns[clean_df.columns.str.contains(\"_MEDI\")])\n",
    "\n",
    "clean_df = clean_df.drop(columns=mode_cols).drop(columns=avg_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "f73991df-8023-4487-b9fd-e3eb94df835a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# code related to created a 'HOUSING SCORE' based on number of housing columns that are above average for that row\n",
    "clean_df = clean_df.reset_index(drop=True)\n",
    "combine = clean_df[med_cols]\n",
    "\n",
    "housing_columns_above_mean_cnt = pd.Series(np.zeros(len(combine.index)))\n",
    "for col in combine.columns:\n",
    "    housing_columns_above_mean_cnt += (combine[col] > combine[col].mean()).astype(int)\n",
    "\n",
    "na_bool_series = [combine[col].isna() for col in combine.columns]\n",
    "undefined_housing_indicies = []\n",
    "for i in range(len(na_bool_series[0])):\n",
    "    if all(l[i] for l in na_bool_series):\n",
    "        undefined_housing_indicies.append(i)\n",
    "        \n",
    "for i in undefined_housing_indicies: housing_columns_above_mean_cnt[i] = 'NO INFO' \n",
    "    \n",
    "clean_df['HOUSING_SCORE'] = housing_columns_above_mean_cnt\n",
    "# dropping the original columns\n",
    "clean_df = clean_df.drop(columns=med_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "6559d8a9-cb72-44d7-8282-99231064bc21",
   "metadata": {},
   "outputs": [],
   "source": [
    "# final filter to get columns with only known housing scores\n",
    "clean_df_2 = clean_df[clean_df['HOUSING_SCORE'] != 'NO INFO']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "fc2d306e-1f72-4878-b88a-9eb5872aadc5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [name, count]\n",
       "Index: []"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check for missing values\n",
    "test = pd.DataFrame(clean_df.isna().sum()).reset_index()\n",
    "test.columns = ['name', 'count']\n",
    "test[test['count'] > 0 ]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae379b01-bcd6-42cf-bb38-1387a1f0955a",
   "metadata": {},
   "source": [
    "## Adding Additional Features from Supplemental Tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "0630e8b9-972b-409b-98da-9269b94afeac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# removing flag document columns\n",
    "clean_df_2 = clean_df_2.drop(clean_df_2.loc[:,'FLAG_DOCUMENT_2':'FLAG_DOCUMENT_21' ].columns, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "b4d31dd3-99ed-4e4e-a96c-0558f8856234",
   "metadata": {},
   "outputs": [],
   "source": [
    "# reading in additional tables\n",
    "df_credit = pd.read_csv(PATH_EXTRA+'credit_card_balance.csv')\n",
    "df_prev = pd.read_csv(PATH_EXTRA+'previous_application.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a15366c-fbd2-4a33-8f4a-fafb9a4262f1",
   "metadata": {},
   "source": [
    "### Average Annuity Credit Ratio from Previous Loans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "0ce116f1-dcce-4855-bceb-f5c0834bd09f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get average annuity credit ratio for previous applications\n",
    "df_prev['ANNUITY_CREDIT_RATIO'] = df_prev['AMT_ANNUITY']/df_prev['AMT_CREDIT']\n",
    "avg_ann_cred_ratio = pd.DataFrame(df_prev.groupby('SK_ID_CURR')['ANNUITY_CREDIT_RATIO'].mean()).reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "452e0f05-2882-428f-a42e-c8905ef0635d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# merge in new feature\n",
    "df_clean = clean_df_2.merge(avg_ann_cred_ratio, on='SK_ID_CURR', how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "093676df-d046-493b-a796-ae72dd92770f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_clean = df_clean[df_clean['ANNUITY_CREDIT_RATIO'].notnull()]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9f293f3-40bc-4882-a9c4-c2aadd6c2180",
   "metadata": {},
   "source": [
    "### Number of Months of Missed Minimum Payments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "ee071450-b4d2-4a40-bf28-0d1285344306",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_credit['payment diff'] = df_credit['AMT_PAYMENT_CURRENT'] - df_credit['AMT_INST_MIN_REGULARITY']\n",
    "df_credit['CNT_MISSED_MIN'] = np.where(df_credit['payment diff'] < 0, 1, 0)\n",
    "\n",
    "cnt_missed_min = pd.DataFrame(df_credit.groupby('SK_ID_CURR')['CNT_MISSED_MIN'].sum()).reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "12d288c4-6dbe-44c4-abda-39c0ccd98a9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# merge in new feature\n",
    "df_clean = df_clean.merge(cnt_missed_min, on='SK_ID_CURR', how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "c858a68c-048b-45c0-b2fe-76935ca3f3b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# fill in 0 if never missed min\n",
    "df_clean['CNT_MISSED_MIN'].fillna(0, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb411678-0ca3-49db-9b37-554b8ade7486",
   "metadata": {},
   "source": [
    "### Number of Previous Total Applied Loans & Number of Previous Accepted Loans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "a5a7d6e8-abb4-4cff-8f49-2b22cfc93dc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# previous total amount of applied loans per id\n",
    "prev_loan_cnt = pd.DataFrame(df_prev['SK_ID_CURR'].value_counts()).reset_index()\n",
    "prev_loan_cnt.columns = ['SK_ID_CURR', 'CNT_PREV_LOANS']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "a9b4351e-76eb-4dae-b101-37a6b46fb4c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# previous total amount of accepted loans per id\n",
    "prev_acc_loan = pd.DataFrame(df_prev[df_prev['NAME_CONTRACT_STATUS'] == 'Approved']['SK_ID_CURR'].value_counts()).reset_index()\n",
    "prev_acc_loan.columns = ['SK_ID_CURR', 'CNT_ACCEPTED_LOANS']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "77e45efa-6ed8-4c40-bd35-e4af0959dbdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# merge in new feature\n",
    "df_clean = df_clean.merge(prev_loan_cnt, on='SK_ID_CURR', how='left')\n",
    "df_clean = df_clean.merge(prev_acc_loan, on='SK_ID_CURR', how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "70255f3c-1460-44c9-884b-d95b02116435",
   "metadata": {},
   "outputs": [],
   "source": [
    "# if there is missing data means they never previously applied for loan -> fill in with 0\n",
    "df_clean['CNT_PREV_LOANS'].fillna(0, inplace=True)\n",
    "df_clean['CNT_ACCEPTED_LOANS'].fillna(0, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "ed77f23b-5371-443d-85e3-90cfa93820a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_clean = df_clean.rename(columns={'ANNUITY_CREDIT_RATIO':'PREV_AVG_AC_RATIO'})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7959608b",
   "metadata": {},
   "source": [
    "### Bureau data: creating financial bureau score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "0887c212",
   "metadata": {},
   "outputs": [],
   "source": [
    "bb = pd.read_csv(PATH_EXTRA+'bureau_balance.csv')\n",
    "b = pd.read_csv(PATH_EXTRA+'bureau.csv')\n",
    "\n",
    "bb = bb.drop('MONTHS_BALANCE', axis=1)\n",
    "# I dropped months_balance, because it seems mostly useless as were are only looking to penalize late payments, and not consider on time ones. \n",
    "\n",
    "b = b.loc[:, ['SK_ID_CURR', 'SK_ID_BUREAU', 'AMT_CREDIT_SUM_OVERDUE', 'AMT_CREDIT_MAX_OVERDUE', 'CREDIT_DAY_OVERDUE', 'AMT_CREDIT_SUM']]\n",
    "# After redeaing through the bureau.csv descriptions, only this subset seems useful for our calculations.\n",
    "\n",
    "bb = bb[(bb.STATUS != 'X') & (bb.STATUS != 'C') & (bb.STATUS != '0')] # Only want to see bad examples, not good ones\n",
    "bb.STATUS = bb.STATUS.astype(int)\n",
    "\n",
    "comb = pd.merge(b, bb, on='SK_ID_BUREAU', how='left').fillna(0).groupby(['SK_ID_CURR']).sum().drop('SK_ID_BUREAU', axis=1).add_prefix('SUM_OF_')\n",
    "# Going to replace NA values with 0, seems resonable because other columns are usually 0. Did outer join so we don't eliminate those without a status\n",
    "\n",
    "df_clean = pd.merge(df_clean, comb, on='SK_ID_CURR')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c1deedd",
   "metadata": {},
   "source": [
    "### Dimensionality reductions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "2e04d009",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_clean = df_clean.drop('FLAG_MOBIL', axis=1) # breaks gradient descent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "87f4c5f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# converting binary column\n",
    "for col in df_clean.columns:\n",
    "    if len(df_clean[col].unique()) == 2:\n",
    "        df_clean[col] = pd.Series(np.where(df_clean[col].values == df_clean[col].unique()[0], 1, 0), df_clean.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "78905904-c5e9-4483-9b10-6bf845a5504c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SK_ID_CURR</th>\n",
       "      <th>TARGET</th>\n",
       "      <th>NAME_CONTRACT_TYPE</th>\n",
       "      <th>CODE_GENDER</th>\n",
       "      <th>FLAG_OWN_CAR</th>\n",
       "      <th>FLAG_OWN_REALTY</th>\n",
       "      <th>AMT_INCOME_TOTAL</th>\n",
       "      <th>AMT_CREDIT</th>\n",
       "      <th>AMT_ANNUITY</th>\n",
       "      <th>NAME_TYPE_SUITE</th>\n",
       "      <th>...</th>\n",
       "      <th>HOUSING_SCORE</th>\n",
       "      <th>PREV_AVG_AC_RATIO</th>\n",
       "      <th>CNT_MISSED_MIN</th>\n",
       "      <th>CNT_PREV_LOANS</th>\n",
       "      <th>CNT_ACCEPTED_LOANS</th>\n",
       "      <th>SUM_OF_AMT_CREDIT_SUM_OVERDUE</th>\n",
       "      <th>SUM_OF_AMT_CREDIT_MAX_OVERDUE</th>\n",
       "      <th>SUM_OF_CREDIT_DAY_OVERDUE</th>\n",
       "      <th>SUM_OF_AMT_CREDIT_SUM</th>\n",
       "      <th>SUM_OF_STATUS</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>100002</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>M</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>202500.0</td>\n",
       "      <td>406597.5</td>\n",
       "      <td>24700.5</td>\n",
       "      <td>Unaccompanied</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.051670</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>30053.79</td>\n",
       "      <td>0</td>\n",
       "      <td>4343645.565</td>\n",
       "      <td>27.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>100016</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>F</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>67500.0</td>\n",
       "      <td>80865.0</td>\n",
       "      <td>5881.5</td>\n",
       "      <td>Unaccompanied</td>\n",
       "      <td>...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.102497</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0</td>\n",
       "      <td>474984.000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>100017</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>M</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>225000.0</td>\n",
       "      <td>918468.0</td>\n",
       "      <td>28966.5</td>\n",
       "      <td>Unaccompanied</td>\n",
       "      <td>...</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0.085245</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0</td>\n",
       "      <td>859770.000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>100022</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>F</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>112500.0</td>\n",
       "      <td>157500.0</td>\n",
       "      <td>7875.0</td>\n",
       "      <td>Accompanied</td>\n",
       "      <td>...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.065560</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0</td>\n",
       "      <td>1057500.000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>100026</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>F</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>450000.0</td>\n",
       "      <td>497520.0</td>\n",
       "      <td>32521.5</td>\n",
       "      <td>Unaccompanied</td>\n",
       "      <td>...</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.117923</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0</td>\n",
       "      <td>5625000.000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 50 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   SK_ID_CURR  TARGET  NAME_CONTRACT_TYPE CODE_GENDER  FLAG_OWN_CAR  \\\n",
       "0      100002       1                   1           M             1   \n",
       "1      100016       0                   1           F             1   \n",
       "2      100017       0                   1           M             0   \n",
       "3      100022       0                   0           F             1   \n",
       "4      100026       0                   1           F             1   \n",
       "\n",
       "   FLAG_OWN_REALTY  AMT_INCOME_TOTAL  AMT_CREDIT  AMT_ANNUITY NAME_TYPE_SUITE  \\\n",
       "0                1          202500.0    406597.5      24700.5   Unaccompanied   \n",
       "1                1           67500.0     80865.0       5881.5   Unaccompanied   \n",
       "2                0          225000.0    918468.0      28966.5   Unaccompanied   \n",
       "3                1          112500.0    157500.0       7875.0     Accompanied   \n",
       "4                0          450000.0    497520.0      32521.5   Unaccompanied   \n",
       "\n",
       "   ... HOUSING_SCORE PREV_AVG_AC_RATIO CNT_MISSED_MIN CNT_PREV_LOANS  \\\n",
       "0  ...           0.0          0.051670            0.0              1   \n",
       "1  ...           2.0          0.102497            0.0              4   \n",
       "2  ...           7.0          0.085245            0.0              2   \n",
       "3  ...           2.0          0.065560            0.0              1   \n",
       "4  ...           3.0          0.117923            0.0              3   \n",
       "\n",
       "   CNT_ACCEPTED_LOANS  SUM_OF_AMT_CREDIT_SUM_OVERDUE  \\\n",
       "0                 1.0                            0.0   \n",
       "1                 4.0                            0.0   \n",
       "2                 2.0                            0.0   \n",
       "3                 1.0                            0.0   \n",
       "4                 2.0                            0.0   \n",
       "\n",
       "   SUM_OF_AMT_CREDIT_MAX_OVERDUE  SUM_OF_CREDIT_DAY_OVERDUE  \\\n",
       "0                       30053.79                          0   \n",
       "1                           0.00                          0   \n",
       "2                           0.00                          0   \n",
       "3                           0.00                          0   \n",
       "4                           0.00                          0   \n",
       "\n",
       "   SUM_OF_AMT_CREDIT_SUM SUM_OF_STATUS  \n",
       "0            4343645.565          27.0  \n",
       "1             474984.000           0.0  \n",
       "2             859770.000           0.0  \n",
       "3            1057500.000           0.0  \n",
       "4            5625000.000           0.0  \n",
       "\n",
       "[5 rows x 50 columns]"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# export to csv\n",
    "df_clean.to_csv('cleaned_training_data.csv', index=False)\n",
    "df_clean.head()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "vscode": {
   "interpreter": {
    "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
